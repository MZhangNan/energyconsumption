{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the script for predting the building energy consumption \n",
    "# our strategy is : \n",
    "   ##  1. Clear and careful data cleanning and data feature (seperate job for liubo), aims to clean the data and add as many useful features as possible.\n",
    "   ##  2. Ensemble training models for final prediction; split the training dataset based on four catergories: \n",
    "            # a. building stories (let 25 as the building story threshold, can be discussed)\n",
    "            # b. HACV system type\n",
    "            # c. meter types\n",
    "            # d. time span (before 2017 and after 2017)\n",
    "          # According to different combination of dataset, we can create 21 different type models, for each model, we use 3 differet type of ML approaches for training, so in total, we will have 21*3 = 63 models for final selection and ensemble\n",
    "   ## 3. Model validation appraoch\n",
    "           # choose number 5 building as the validation model since this building info is close to target building with 29 stroies and same HACV system.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/Users/nanzhang/Documents/GitHub/energyconsumption\n1.0.3\n"
    }
   ],
   "source": [
    "# this script is to do the data cleaning, visualization and adding new features\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import os, sys, gc, warnings, random, datetime, math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "matplotlib.rcParams['figure.dpi'] = 100\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"./data/0516_data.pkl\")\n",
    "test  = pd.read_csv(\"./data/result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the datatype\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mem. usage decreased to 52.95 Mb (56.6% reduction)\n"
    }
   ],
   "source": [
    "train  =  reduce_mem_usage(train)\n",
    "train.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class ModelWrapper:\n",
    "    name: str\n",
    "    model: 'typing.Any'\n",
    "    hyper: dict\n",
    "    path: str\n",
    "    _estimator: 'typing.Any' = None\n",
    "        \n",
    "    @property\n",
    "    def estimator(self):\n",
    "        if self._estimator is None:\n",
    "            self._estimator = self.model(**self.hyper)\n",
    "\n",
    "        return self._estimator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "\n",
    "# build the logic for constructing necessary models\n",
    "SEED = 42\n",
    "config = [\n",
    "   ('H', 'Stair1', 25),\n",
    "   ('C', 'HVACType', '集中式全空'),\n",
    "   ('Y', 'Time', [2017,1,1])\n",
    "]\n",
    "config1=[0,1,2]\n",
    "lgb_params = {\n",
    "            'objective':'binary',\n",
    "            'boosting_type':'gbdt',\n",
    "            'metric':'auc',\n",
    "            'n_jobs':-1,\n",
    "            'learning_rate':0.01,\n",
    "            'num_leaves': 2**8,\n",
    "            'max_depth':-1,\n",
    "            'tree_learner':'serial',\n",
    "            'colsample_bytree': 0.7,\n",
    "            'subsample_freq':1,\n",
    "            'subsample':0.7,\n",
    "            'n_estimators':80000,\n",
    "            'max_bin':255,\n",
    "            'verbose':-1,\n",
    "            'seed': SEED,\n",
    "            'early_stopping_rounds':100, \n",
    "                } \n",
    "MODELS = [\n",
    "    ModelWrapper(name='log', model=linear_model.LogisticRegression, hyper={'max_iter': 100, 'penalty': 'l2', 'dual': False, \n",
    "                                               'solver': 'liblinear', 'C': 0.5}, path = ''),\n",
    "    ModelWrapper(name='rfc-1', model=ensemble.RandomForestClassifier, hyper={'n_estimators': 2}, path = ''),\n",
    "    ModelWrapper(name='lgb', model=lgb, hyper=lgb_params, path = ''),    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['01', '02', '12']\n"
    }
   ],
   "source": [
    "def combination_k(s, k):\n",
    "    if k == 0: return ['']\n",
    "    subletters = []\n",
    "    # 此处涉及到一个 python 遍历循环的特点：当遍历的对象为空（列表，字符串...）时，循环不会被执行，range(0) 也是一样\n",
    "    for i in range(len(s)):\n",
    "        for letter in combination_k(s[i+1:], k-1):\n",
    "            subletters += [str(s[i]) + str(letter)]\n",
    "    return subletters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing loop for filter differet train set for train\n",
    "validat_set = train[train['BuildingID'] == 5]\n",
    "train = train[train['BuildingID'] != 5]\n",
    "record =[]\n",
    "for i in range (1,5):\n",
    "    combs = combination_k(config1, i)\n",
    "    for com in combs:\n",
    "        logger.info(f'processing the train data with combine of {com}')\n",
    "        train_set  = fliter_data(train, com)\n",
    "        # output the best model path \n",
    "        Best_paths = train_model(train_set, MODELS, com)\n",
    "         # output the validation mse result under best model\n",
    "        val_result = valida_model(Best_paths, validat_set)\n",
    "        record.append({com: [Best_paths, val_result]})\n",
    "print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fliter_data(train, com):\n",
    "    for con in com:\n",
    "        conf =  config[int(con)]\n",
    "        train = do_filter_data(train, conf)\n",
    "    return train\n",
    "\n",
    "def do_filter_data(train, conf):\n",
    "    if conf[0] == 'H':\n",
    "        train = train[train[conf[1] >= conf[2]]]\n",
    "    elif conf[0] == 'C':\n",
    "        train = train[train[conf[1] == conf[2]]]\n",
    "    elif conf[0] == 'Y':\n",
    "        train = train[train[conf[1] >= pd.Timestamp(conf[2][0], conf[2][1], conf[2][2])]]\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from typing import Tuple\n",
    "from sklearn.externals import joblib\n",
    "# here we use three models for training C\n",
    "def train_model(train_set, models: List[ModelWrapper], com):\n",
    "\n",
    "    Types =['W/Q', 'Q', 'W']\n",
    "    best =[]\n",
    "    for Type in Types:\n",
    "\n",
    "        if Type =='W/Q':\n",
    "            train_feed = train_set\n",
    "        else:\n",
    "            train_feed = train_set[train_set['Type']= Type]\n",
    "\n",
    "        X, y, feature_names = scale_features(train_feed)\n",
    "\n",
    "        best_modelwrapper = find_best_model(X, y, models)\n",
    "\n",
    "        path = fit_and_save(X, y, best_modelwrapper, com, Type)\n",
    "\n",
    "        best.append(path)\n",
    "\n",
    "        logger.info(f'''best model for Type ={Type} and data type {com} is {best_modelwrapper.name}''')\n",
    "\n",
    "    return best\n",
    "\n",
    "def scale_features(df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, list]:\n",
    "    \"\"\" \n",
    "        1. Scale features - necessary step for some models\n",
    "        2. Extract the X & y matrices\n",
    "    \"\"\"\n",
    "    logger.info('scaling features... ')\n",
    "    # Extract arrays\n",
    "    y = df['Record'].values\n",
    "    \n",
    "    # lab_enc = preprocessing.LabelEncoder()\n",
    "    # y = lab_enc.fit_transform(y)\n",
    "    \n",
    "    X = df.drop(['Record', 'Time'], axis='columns').values\n",
    "    feature_names = df.drop('Record', axis='columns').columns.tolist()\n",
    "    \n",
    "    # Scale\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    logger.info(X.shape)\n",
    "\n",
    "    return X, y, feature_names\n",
    "\n",
    "def find_best_model(X: np.ndarray, y: np.ndarray, models: List[ModelWrapper]) -> ModelWrapper:\n",
    "    \"\"\" Completely new function\n",
    "            1. Iterate each model defined in the MODELS list\n",
    "            2. Get the Cross Validated AUC for it\n",
    "            3. Select the best model based on AUC, and returns it\n",
    "    \"\"\"\n",
    "    # test all models\n",
    "    results = []\n",
    "    for modelwrapper in models:\n",
    "        logger.info(f'*** Training {modelwrapper.name} ***')\n",
    "        scores = cross_validation(X, y, modelwrapper.estimator)\n",
    "        results.append([scores.mean(), modelwrapper])\n",
    "\n",
    "    # find best model\n",
    "    best_modelwrapper = sorted(results, key=lambda k: k[0], reverse=True)[0][1]\n",
    "    logger.info(f'*** Best model is {best_modelwrapper.name} ***')\n",
    "    return best_modelwrapper\n",
    "\n",
    "def fit_and_save(X: np.ndarray, y: np.ndarray, model: ModelWrapper, com, Type) -> ModelWrapper:\n",
    "    \"\"\"\n",
    "        Slight adapation of the previous code to receive the ModelWrapper\n",
    "    \"\"\"\n",
    "    logger.info('training model')\n",
    "    model.estimator.fit(X, y)\n",
    "\n",
    "    path = f'models/{Type}_{com}_{model.name}.model' ## MODIFIED TO USE THE ModelWrapper Class\n",
    "    logger.info(f'saving model in {path}')\n",
    "    joblib.dump(model.estimator, path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "\"\"\"\n",
    "    root_mean_squared_log_error\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_log_error\n",
    "    np.sqrt(mean_squared_log_error(y_test, predictions))\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "def cross_validation(X, y, estimator, n_jobs: int=1):\n",
    "    \"\"\"\n",
    "        Cross validation (CV) is a common technique used to test the stability of a prediction.\n",
    "        CV Warns us if we're overfitting\n",
    "        In other words, CV help us select the model which will perform best on unseen data.\n",
    "    \"\"\"\n",
    "    logger.info('Cross Validation')\n",
    "    # cross_validation\n",
    "    cv = model_selection.ShuffleSplit(n_splits=5,\n",
    "                                      test_size=0.2,\n",
    "                                      random_state=0\n",
    "                                      )\n",
    "\n",
    "\n",
    "    scores = model_selection.cross_val_score(estimator,\n",
    "                                                 X,\n",
    "                                                 y,\n",
    "                                                 cv=cv,\n",
    "                                                 scoring='mean_squared_error',\n",
    "                                                 n_jobs=n_jobs\n",
    "                                                 )\n",
    "    scores = np.sqrt(scores)\n",
    "    logger.info('CV performance:')\n",
    "    logger.info(\n",
    "        \"mean_squared_log_error: {:.2f} % (+/- {:.2f} )\".format(scores.mean() * 100,\n",
    "                                                        scores.std() * 2 * 100\n",
    "                                                  )\n",
    "                )\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valida_model(Best_paths, validat_set, com):\n",
    "\n",
    "    Types =['W/Q', 'Q', 'W']\n",
    "    val_results =[]\n",
    "    for Type in Types:\n",
    "\n",
    "        model_path =  [for path in Best_paths if Type in path]\n",
    "\n",
    "        if Type =='W/Q':\n",
    "            train_feed = validat_set\n",
    "            \n",
    "        else:\n",
    "            train_feed = validat_set[train_set['Type']= Type]\n",
    "\n",
    "        X, y, feature_names = scale_features(train_feed)\n",
    "\n",
    "        result = load_and_predict(X, y, model_path)\n",
    "\n",
    "        val_results.append(path)\n",
    "\n",
    "        logger.info(f'''The validation results for Type ={Type} and data type {com} is {result}''')\n",
    "\n",
    "    return val_results\n",
    "\n",
    "\n",
    "def load_and_predict(X, y, model_path):\n",
    "    estimator = joblib.load(model_path[0])\n",
    "    pre_y = estimator.predict(X)\n",
    "    result = rmse(pre_y, y)\n",
    "    return result\n",
    "\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "\n",
    "    differences = predictions - targets                       #the DIFFERENCEs.\n",
    "\n",
    "    differences_squared = differences ** 2                    #the SQUAREs of ^\n",
    "\n",
    "    mean_of_differences_squared = differences_squared.mean()  #the MEAN of ^\n",
    "\n",
    "    rmse_val = np.sqrt(mean_of_differences_squared)/ targets.mean()  #ROOT of ^/ MEAN of target\n",
    "\n",
    "    return rmse_val "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}